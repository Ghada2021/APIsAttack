# -*- coding: utf-8 -*-
"""Untitled33.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/114eDmBK-fzroqR8U9Me39syfQpyztYJm
"""

import pandas as pd
import numpy as np
import random

data= pd.read_csv("supervised_dataset.csv")

for i in range(len(data)):
    if data['classification'].iloc[i] == 'normal':
        data.loc[i, 'Security Type'] = 'OAuth'
    elif data['classification'].iloc[i] == 'outlier':
        data.loc[i, 'Security Type'] = 'ApiKey'

import pandas as pd
import seaborn as sn
import numpy as np
import xgboost
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import BaggingClassifier
from sklearn.ensemble import AdaBoostClassifier,RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from sklearn.tree import DecisionTreeClassifier
from keras.models import  Sequential
from keras.layers import Dense
import keras.activations,keras.metrics,keras.losses


data['inter_api_access_duration(sec)']=data['inter_api_access_duration(sec)'].fillna(data['inter_api_access_duration(sec)'].mean())
data['api_access_uniqueness']=data['api_access_uniqueness'].fillna(data['api_access_uniqueness'].mean())

sn.heatmap(data.corr())
plt.show()


plt.figure(figsize=(17,6))
corr = data.corr(method='kendall')
my_m=np.triu(corr)
sn.heatmap(corr, mask=my_m, annot=True, cmap="Set2")
plt.show()

print(data.isna().sum())
print()
for i in data.columns.values:
    if len(data[i].value_counts()) <5:
        print(i)

print()
cat_col=data.select_dtypes(include='object').columns.values

lab=LabelEncoder()
data['type_ip']=lab.fit_transform(data['ip_type'])
data['sources']=lab.fit_transform(data['source'])
data['classifiction']=lab.fit_transform(data['classification'])
print()
print(data.columns.values)
x=data[['sequence_length(count)','vsession_duration(min)'
 ,'num_sessions','num_users' ,'num_unique_apis'
 ,'type_ip','sources']]
y=data['classifiction']

print(data['classifiction'].value_counts())


x_train,x_test,y_train,y_test=train_test_split(x,y)

lr=LogisticRegression(max_iter=200)
lr.fit(x_train,y_train)
print('The logistic regression: ',lr.score(x_test,y_test))

xgb=XGBClassifier()
xgb.fit(x_train,y_train)
print("the Xgb : ",xgb.score(x_test,y_test))

lgb=LGBMClassifier()
lgb.fit(x_train,y_train)
print('The LGB',lgb.score(x_test,y_test))

tree=DecisionTreeClassifier(criterion='entropy',max_depth=1)
tree.fit(x_train,y_train)
print('Dtree ',tree.score(x_test,y_test))

rforest=RandomForestClassifier(criterion='entropy')
rforest.fit(x_train,y_train)
print('The random forest: ',rforest.score(x_test,y_test))

adb=AdaBoostClassifier()
adb.fit(x_train,y_train)
print('the adb ',adb.score(x_test,y_test))

grb=GradientBoostingClassifier()
grb.fit(x_train,y_train)
print('Gradient boosting ',grb.score(x_test,y_test))

bag=BaggingClassifier()
bag.fit(x_train,y_train)
print('Bagging',bag.score(x_test,y_test))
print('-----------------------------------')

models=Sequential()
models.add(Dense(units=x.shape[1],input_dim=x.shape[1],activation=keras.activations.sigmoid))
models.add(Dense(units=x.shape[1],activation=keras.activations.sigmoid))
models.add(Dense(units=x.shape[1],activation=keras.activations.relu))
models.add(Dense(units=x.shape[1],activation=keras.activations.sigmoid))

models.add(Dense(units=1,activation=keras.activations.sigmoid))
models.compile(optimizer='adam',metrics='accuracy',loss=keras.losses.binary_crossentropy)
models.fit(x_train,y_train,batch_size=20,epochs=10)